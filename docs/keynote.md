# Introduction to Diffusion Models —— GIS Lab 2024 Short-term Course

> Presentor: Sakura (Chen Zhenyuan) M.Eng.
>
> Department: School of Earth Science, Zhejiang University
>
> Date: July 2, 2024
>
> Contact me: [bili_sakura@zju.edu.cn](mailto:bili_sakura@zju.edu.cn)

## Copyright Statement

© Sakura, 2024. All rights reserved. This document is protected by copyright law. No part of this publication may be reproduced, distributed, or transmitted in any form or by any means, including photocopying, recording, or other electronic or mechanical methods, without the prior written permission of the author, except in the case of brief quotations embodied in critical reviews and certain other noncommercial uses permitted by copyright law. For permission requests, please contact the author at [bili_sakura@zju.edu.cn](mailto:bili_sakura@zju.edu.cn).

![](../assets/sakura.png)

## Outline

- [Background](#background)

  - Prosperity of Generative Artificial Intelligence (Gen AI)

  - Progress of Deep Generative Models
- [Introduction](#introduction)
  - Generation from Scratch
  - Auto-regression
  - Generalized Auto-regression
  - Denoising Diffusion
- [Techniques of Diffusion Models](#techniques-of-diffusion-models)
  - Evolution of Architectures
  - Conditional Generation
  - Robustness

- [Diffusion Model in Remote Sensing (RS)](#diffusion-model-in-remote-sensing)
  - section1
  - section2
  - section3
- [**Practice on Diffusion Model**](#practice-on-diffusion-model)

## Background

### Prosperity of Gen AI: Midjourney

<div align="center"><img src="../assets/midjourney_cases.png"><p>Awesome pictures generated by Midjourney V5.*
</p></div>

> <https://legacy.midjourney.com/showcase/>

### Prosperity of Gen AI: DALL·E 3

<div align="center"><img src="../assets/DALLE-3_case1_full.png"><img src="../assets/DALLE-3_case2_full.png"><p>DALL·E 3 is capable of understanding complex instructions.*</p></div>

> <https://openai.com/blog/dall-e-3-is-now-available-in-chatgpt-plus-and-enterprise>

### Prosperity of Gen AI: Gen-2

<div align="center"><img src="../assets/WebGEN2R_T2V.gif"><p>Text to Video by Gen-2. *</p><p> (The late afternoon sun peeking through the window of a New York City loft.)</p></div>

> <https://research.runwayml.com/gen2>

### Prosperity of Gen AI: Pika

<div align="center"><img src="../assets/cinematic,_aerial_drone_flythough_over_seashore_of_the_vast_mountain_cliffs_of_Scotland,_strong_bree_seed6089107589751151_upscaled.gif"><p>Text to Video. *</p><p>(cinematic, aerial drone flythough over seashore of the vast mountain cliffs of Scotland, strong breeze blowing hair and strong ocean waves, dolly in)</p></div>

> <https://pika.art/>

### Progress of Deep Generative Models

<div align="center"><img src="../assets/timeline_of_gen.png"><p>Progress of deep generative models [1]. </p></div>

## Introduction

### Generation from Scratch

<div align="center"><img src="../assets/illustration_of_cnn.png"></div>

<div align="center">
<div style="display: flex; justify-content: center;">
    <img src="../assets/video_clip0.gif">
    <img src="../assets/video_clip1.gif">
</div>
  <p>Why Naïve Generation Doesn't Work. *</p>
<div style="display: flex; justify-content: center;">
    <img src="../assets/average_for_label.jpg" width="50%">
    <img src="../assets/video_clip2.gif">
</div>
<p>Left: Average makes sense in label prediction.*</p>
<p>Right: Average does not make sense in pixel level prediction.*</p>
</div>

### Auto-regression

<div align="center">
<div style="display: flex; justify-content: center;">
    <img src="../assets/video_clip3.gif">
    <img src="../assets/video_clip4.gif">
</div>
<p>Left: A neural network (purple) predicts the last pixel.*</p>
<p>Right: A neural network (pink) predicts the second last pixel.*</p>
</div>
<div align="center">
    <img src="../assets/video_clip5.gif" width="150%">
<p>We succeed in generating an image from nothing by predicting the next pixel.*</p>
</div>
<div align="center">
<div style="display: flex; justify-content: center;">
    <img src="../assets/pixel_probability.jpg" width="50%">
    <img src="../assets/video_clip6.gif">
</div>
<p>Left: A determined neural network give the identical result 
given the same first pixel value. *</p>
<p>Right: We can randomly sample pixel value in each step to generate different images from identical initial pixel. *</p>
</div>


<div align="center">
    <img src="../assets/video_clip7.gif">
<p> Auto regressor for image generation. *</p>
    <img src="../assets/gpt-2-autoregression-2.gif">
<p>Auto regressor for text generation. *</p>
</div>

> <https://www.youtube.com/watch?v=zc5NTeJbk-k>

### Generalized Auto-regression

<div align="center">
<img src="../assets/video_clip8.gif">
<p>Predict a whole block instead of single pixel.*</p>
<img src="../assets/average_plausible_results.png">
<p>Average in pixel value leads to non-sense.*</p>
<img src="../assets/independent_pixel_prediction.png">
<p>We can feel free to predict any pixel seperately, if pixel value is statistically independent.*</p>
    <img src="../assets/similarity_in_image.png">
    <p>It is noted that near pixels are the most strongly related, because they are usaually part of the same object.*</p>
    <img src="../assets/remove_seperately_cases.png">
    <p>Remove separate pixels from the image and train a network to predict them (as these pixels are far from each other, we regard them as independent).*
</p>
</div>


<div align="center">
    <img src="../assets/video_clip9.gif">
<p> Remove indepedent pixels graudually (the reversed process is to predict the image).*</p>
</div>

<div align="center">
    <img src="../assets/regressor_recover_process_full.png">
<p> Auto regressor generate images in two steps (add masks & remove masks).*</p>
</div>

<div align="center">
    <img src="../assets/PixelCNN_overview.png">
<p> Illustration of PixelCNN [5].(Left: To generate pixel xi one conditions on all the previously generated pixels left and above of xi. Center: To generate a pixel in the multi-scale case we can also condition on the subsampled image pixels. Right: Diagram of the connectivity inside a masked convolution. In the first layer, each of the RGB channels is connected to previous channels and to the context, but is not connected to itself. In subsequent layers, the channels are also connected to themselves.)</p>
</div>



> <https://www.youtube.com/watch?v=zc5NTeJbk-k>

### Denoising Diffusion

<div align="center">
    <img src="../assets/video_clip10.gif">
<p> Remove information by add noise rather than completely remove pixels.*</p>
</div>

> <https://www.youtube.com/watch?v=zc5NTeJbk-k>

<div align="center">
    <img src="../assets/add_noice_full.png">
    <img src="../assets/denoice_full.png">
</div>

## Techniques of Diffusion Models

### Evolution of Architectures

<div align="center"><img src="../assets/Evolution_of_Architectures.png"></div>

### Conditional Generation

### Robustness

## Diffusion Model in Remote Sensing


## Practice on Diffusion Model

## References

[1] Z. Deng, "扩散模型: 方法与应用" [Advanced Neural Networks, Spring, 2024], Qing Yuan Research Institute, Shanghai Jiao Tong University, 2024.

[2] K. Simonyan and A. Zisserman, ‘Very Deep Convolutional Networks for Large-Scale Image Recognition’, in International Conference on Learning Representations, 2014. 

[3] W. Yu, K. Yang, T. Xiao, H. Yao, and Y. Rui, ‘Visualizing and Comparing AlexNet and VGG using Deconvolutional Layers’, 2016. 

[4] O. Russakovsky et al., ‘ImageNet Large Scale Visual Recognition Challenge’. arXiv, Jan. 29, 2015. 

[5] A. van den Oord, N. Kalchbrenner, and K. Kavukcuoglu, ‘Pixel Recurrent Neural Networks’, in Proceedings of The 33rd International Conference on Machine Learning, PMLR, Jun. 2016, pp. 1747–1756. 

[6] Y. Song, J. Sohl-Dickstein, D. P. Kingma, A. Kumar, S. Ermon, and B. Poole, ‘Score-Based Generative Modeling through Stochastic Differential Equations’, presented at the International Conference on Learning Representations, Oct. 2020. 

[7] J. Sohl-Dickstein, E. Weiss, N. Maheswaranathan, and S. Ganguli, ‘Deep Unsupervised Learning using Nonequilibrium Thermodynamics’, in Proceedings of the 32nd International Conference on Machine Learning, PMLR, Jun. 2015, pp. 2256–2265. 

[8] F. Bao et al., ‘All Are Worth Words: A ViT Backbone for Diffusion Models’, presented at the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2023, pp. 22669–22679.

[9] A. Dosovitskiy et al., ‘An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale’, in International Conference on Learning Representations, Oct. 2020. 

[10] O. Ronneberger, P. Fischer, and T. Brox, ‘U-Net: Convolutional Networks for Biomedical Image Segmentation’, in International Conference on Medical Image Computing and Computer-Assisted Intervention, N. Navab, J. Hornegger, W. M. Wells, and A. F. Frangi, Eds., Cham: Springer International Publishing, 2015, pp. 234–241.

[11] H. Gao, H. Zhang, Y. Dong, and Z. Deng, ‘Evaluating the Robustness of Text-to-image Diffusion Models against Real-world Attacks’. arXiv, Jun. 15, 2023.
